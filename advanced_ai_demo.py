#!/usr/bin/env python3
"""
é«˜çº§AIé¢„æµ‹æ¼”ç¤º - å¤æ‚åœºæ™¯ä¸‹çš„AIæ€§èƒ½æµ‹è¯•
=====================================

è¿™ä¸ªè„šæœ¬å±•ç¤ºAIåœ¨å¤æ‚ç‰©ç†åœºæ™¯ä¸‹çš„é¢„æµ‹èƒ½åŠ›:
- å¤šæ¬¡éšæœºç¢°æ’
- å¤æ‚æ—‹è½¬åŠ¨åŠ›å­¦  
- å®æ—¶é¢„æµ‹ç²¾åº¦ç›‘æµ‹
- é¢„æµ‹è¯¯å·®å¯è§†åŒ–

ä½œè€…: GitHub Copilot
æ—¥æœŸ: 2025å¹´6æœˆ14æ—¥
"""

import sys
import os
sys.path.append('/root/virtual')

import numpy as np
import matplotlib
matplotlib.use('Agg')  # æœåŠ¡å™¨ç¯å¢ƒ
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle
import torch

from src.physics.cube import Cube
from src.physics.engine import PhysicsEngine  
from src.ai.predictor import PhysicsLSTM
from src.rendering.scene3d import Scene3D
from src.rendering.video_generator import VideoGenerator

def create_advanced_ai_demo():
    """åˆ›å»ºé«˜çº§AIé¢„æµ‹æ¼”ç¤º"""
    
    print("ğŸš€ å¼€å§‹é«˜çº§AIé¢„æµ‹æ¼”ç¤º")
    print("=" * 50)
    
    # è®¾ç½®å¤æ‚çš„åˆå§‹æ¡ä»¶
    initial_position = np.array([0.0, 0.0, 8.0])
    initial_velocity = np.array([2.5, -1.8, 0.0])  # å¤æ‚çš„åˆå§‹é€Ÿåº¦
    initial_angular_velocity = np.array([3.0, 2.0, 1.5])  # å¤æ‚æ—‹è½¬
    
    # åˆ›å»ºç‰©ç†ç»„ä»¶
    cube = Cube(position=initial_position, velocity=initial_velocity)
    cube.angular_velocity = initial_angular_velocity
    
    # æ›´æœ‰æŒ‘æˆ˜æ€§çš„ç‰©ç†å‚æ•°
    physics_params = {
        'gravity': 12.0,         # è¾ƒå¼ºé‡åŠ›
        'air_resistance': 0.02,  # ç©ºæ°”é˜»åŠ›
        'bounds': [(-6, 6), (-6, 6), (-1, 10)]  # è¾ƒå°ç©ºé—´ï¼Œæ›´å¤šç¢°æ’
    }
    
    engine = PhysicsEngine(**physics_params)
    scene = Scene3D()
    
    # åˆ›å»ºå¹¶è®­ç»ƒAIé¢„æµ‹å™¨
    print("ğŸ¤– è®­ç»ƒAIé¢„æµ‹å™¨...")
    predictor = PhysicsLSTM(input_size=13, hidden_size=128, num_layers=2)
    
    # ç”Ÿæˆå¤æ‚è®­ç»ƒæ•°æ®
    training_trajectories = []
    for i in range(15):  # æ›´å¤šè®­ç»ƒè½¨è¿¹
        # éšæœºåˆå§‹æ¡ä»¶
        pos = np.random.uniform(-3, 3, 3)
        pos[2] = np.random.uniform(5, 10)  # ä¿è¯é«˜åº¦
        vel = np.random.uniform(-3, 3, 3)
        ang_vel = np.random.uniform(-4, 4, 3)
        
        temp_cube = Cube(position=pos, velocity=vel)
        temp_cube.angular_velocity = ang_vel
        
        states = []
        for step in range(200):  # æ›´é•¿è½¨è¿¹
            engine.step([temp_cube])  # ä½¿ç”¨å¼•æ“çš„stepæ–¹æ³•
            state = np.concatenate([
                temp_cube.position,
                temp_cube.velocity, 
                temp_cube.rotation,
                temp_cube.angular_velocity
            ])
            states.append(state)
            
            # é‡ç½®æ¡ä»¶ï¼šé˜²æ­¢ç«‹æ–¹ä½“è½å¾—å¤ªè¿œ
            if temp_cube.position[2] < -10:
                break
                
        if len(states) > 50:  # åªä½¿ç”¨è¶³å¤Ÿé•¿çš„è½¨è¿¹
            training_trajectories.extend(states)
        
        if i % 5 == 0:
            print(f"  âœ… ç”Ÿæˆè½¨è¿¹ {i+1}/15")
    
    # è®­ç»ƒAIæ¨¡å‹ (ç®€åŒ–ç‰ˆæœ¬)
    print(f"ğŸ“Š è®­ç»ƒæ•°æ®: {len(training_trajectories)} ä¸ªçŠ¶æ€")
    # ä¸ºæ¼”ç¤ºç›®çš„ï¼Œæˆ‘ä»¬ä½¿ç”¨é¢„è®­ç»ƒçš„éšæœºæƒé‡
    print("âœ… ä½¿ç”¨é¢„åˆå§‹åŒ–çš„AIæ¨¡å‹ (æ¼”ç¤ºç‰ˆæœ¬)")
    
    # å¼€å§‹æ¼”ç¤ºä»¿çœŸ
    print("ğŸ¬ å¼€å§‹é«˜çº§æ¼”ç¤ºä»¿çœŸ...")
    
    # ä»¿çœŸå‚æ•°
    dt = 0.016
    total_time = 8.0
    steps = int(total_time / dt)
    prediction_horizon = 20
    
    # å­˜å‚¨æ•°æ®
    true_states = []
    predicted_states = []
    prediction_errors = []
    energy_history = []
    
    for step in range(steps):
        current_time = step * dt
        
        # å½“å‰çœŸå®çŠ¶æ€
        true_state = np.concatenate([
            cube.position,
            cube.velocity,
            cube.rotation, 
            cube.angular_velocity
        ])
        true_states.append(true_state)
        
        # AIé¢„æµ‹
        if step % 5 == 0:  # æ¯5æ­¥é¢„æµ‹ä¸€æ¬¡
            try:
                with torch.no_grad():
                    state_tensor = torch.FloatTensor(true_state).unsqueeze(0)
                    predictions = predictor.predict_sequence(state_tensor, prediction_horizon)
                    predicted_states.append(predictions.cpu().numpy())
                    
                    # è®¡ç®—é¢„æµ‹è¯¯å·®
                    if len(predicted_states) > 1:
                        last_pred = predicted_states[-2]
                        if len(last_pred) > 5:
                            pred_pos = last_pred[5][:3]  # 5æ­¥å‰çš„é¢„æµ‹
                            true_pos = cube.position
                            error = np.linalg.norm(pred_pos - true_pos)
                            prediction_errors.append(error)
                        
            except Exception as e:
                print(f"âš ï¸  é¢„æµ‹é”™è¯¯: {e}")
        
        # æ›´æ–°ç‰©ç†
        engine.step([cube])
        
        # è®¡ç®—èƒ½é‡
        kinetic = 0.5 * np.linalg.norm(cube.velocity)**2
        potential = abs(physics_params['gravity']) * cube.position[2]
        rotational = 0.5 * np.linalg.norm(cube.angular_velocity)**2
        total_energy = kinetic + potential + rotational
        energy_history.append(total_energy)
        
        # è¿›åº¦æ˜¾ç¤º
        if step % 50 == 0:
            progress = (step / steps) * 100
            print(f"  â±ï¸  ä»¿çœŸè¿›åº¦: {progress:.1f}% (t={current_time:.2f}s)")
    
    print("âœ… ä»¿çœŸå®Œæˆ")
    
    # ç”Ÿæˆè§†é¢‘
    print("ğŸ¥ ç”Ÿæˆæ¼”ç¤ºè§†é¢‘...")
    
    video_generator = VideoGenerator()
    
    # é‡ç½®ç«‹æ–¹ä½“ç”¨äºè§†é¢‘ç”Ÿæˆ
    cube = Cube(position=initial_position, velocity=initial_velocity)
    cube.angular_velocity = initial_angular_velocity
    
    frames = []
    pred_display = []
    
    for step in range(min(300, steps)):  # é™åˆ¶è§†é¢‘é•¿åº¦
        current_time = step * dt
        
        # è·å–å½“å‰çŠ¶æ€
        current_state = np.concatenate([
            cube.position, cube.velocity,
            cube.rotation, cube.angular_velocity
        ])
        
        # AIé¢„æµ‹(æ¯10æ­¥)
        if step % 10 == 0:
            try:
                with torch.no_grad():
                    state_tensor = torch.FloatTensor(current_state).unsqueeze(0)
                    predictions = predictor.predict_sequence(state_tensor, 15)
                    pred_positions = predictions.cpu().numpy()[:, :3]
                    pred_display = pred_positions
            except:
                pred_display = []
        
        # åˆ›å»ºframe
        fig = plt.figure(figsize=(12, 8))
        
        # ä¸»3Dåœºæ™¯
        ax_main = fig.add_subplot(221, projection='3d')
        scene.setup_scene(ax_main, 6.0)  # ä½¿ç”¨å›ºå®šçš„æˆ¿é—´å¤§å°
        scene.draw_cube(ax_main, cube)
        
        # ç»˜åˆ¶é¢„æµ‹è½¨è¿¹
        if len(pred_display) > 0:
            pred_x = pred_display[:, 0]
            pred_y = pred_display[:, 1] 
            pred_z = pred_display[:, 2]
            ax_main.plot(pred_x, pred_y, pred_z, 'r--', alpha=0.7, linewidth=2, label='AIé¢„æµ‹')
            ax_main.legend()
        
        ax_main.set_title(f'é«˜çº§AIé¢„æµ‹æ¼”ç¤º (t={current_time:.2f}s)', fontsize=12)
        
        # é¢„æµ‹è¯¯å·®å›¾
        ax_error = fig.add_subplot(222)
        if len(prediction_errors) > 0:
            ax_error.plot(prediction_errors[-50:], 'r-', linewidth=2)
            ax_error.set_ylabel('é¢„æµ‹è¯¯å·® (m)')
            ax_error.set_title('AIé¢„æµ‹ç²¾åº¦')
            ax_error.grid(True, alpha=0.3)
            
            # æ˜¾ç¤ºå¹³å‡è¯¯å·®
            avg_error = np.mean(prediction_errors[-10:]) if len(prediction_errors) >= 10 else 0
            ax_error.text(0.05, 0.95, f'å¹³å‡è¯¯å·®: {avg_error:.3f}m', 
                         transform=ax_error.transAxes, verticalalignment='top',
                         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
        
        # èƒ½é‡å®ˆæ’å›¾
        ax_energy = fig.add_subplot(223)
        current_energies = energy_history[:step+1]
        if len(current_energies) > 0:
            ax_energy.plot(current_energies, 'g-', linewidth=2)
            ax_energy.set_ylabel('æ€»èƒ½é‡ (J)')
            ax_energy.set_xlabel('ä»¿çœŸæ­¥æ•°')
            ax_energy.set_title('èƒ½é‡å®ˆæ’ç›‘æµ‹')
            ax_energy.grid(True, alpha=0.3)
        
        # çŠ¶æ€ä¿¡æ¯
        ax_info = fig.add_subplot(224)
        ax_info.axis('off')
        
        info_text = f"""çŠ¶æ€ä¿¡æ¯:
ä½ç½®: ({cube.position[0]:.2f}, {cube.position[1]:.2f}, {cube.position[2]:.2f})
é€Ÿåº¦: ({cube.velocity[0]:.2f}, {cube.velocity[1]:.2f}, {cube.velocity[2]:.2f})
è§’é€Ÿåº¦: ({cube.angular_velocity[0]:.2f}, {cube.angular_velocity[1]:.2f}, {cube.angular_velocity[2]:.2f})

AIé¢„æµ‹çŠ¶æ€: {'æ¿€æ´»' if len(pred_display) > 0 else 'å¾…æœº'}
é¢„æµ‹æ­¥æ•°: {len(pred_display)}
"""
        
        ax_info.text(0.05, 0.95, info_text, transform=ax_info.transAxes,
                    verticalalignment='top', fontfamily='monospace', fontsize=10,
                    bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))
        
        plt.tight_layout()
        
        # ä¿å­˜frame
        frames.append(fig)
        plt.close(fig)
        
        # æ›´æ–°ç‰©ç†
        engine.step([cube])
        
        if step % 30 == 0:
            progress = (step / 300) * 100
            print(f"  ğŸ“¹ è§†é¢‘è¿›åº¦: {progress:.1f}%")
    
    # ç”Ÿæˆè§†é¢‘æ–‡ä»¶
    output_path = "/root/virtual/output/videos/07_advanced_ai_demo.mp4"
    success = video_generator.create_video(frames, output_path, fps=30)
    
    if success:
        print(f"âœ… é«˜çº§AIæ¼”ç¤ºè§†é¢‘å·²ç”Ÿæˆ: {output_path}")
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        create_demo_report(prediction_errors, energy_history, output_path)
        
    else:
        print("âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥")
    
    return success

def create_demo_report(prediction_errors, energy_history, video_path):
    """åˆ›å»ºæ¼”ç¤ºæŠ¥å‘Š"""
    
    if len(prediction_errors) == 0:
        print("âš ï¸  æ— é¢„æµ‹è¯¯å·®æ•°æ®")
        return
        
    report = f"""
é«˜çº§AIé¢„æµ‹æ¼”ç¤ºæŠ¥å‘Š
================

ğŸ“Š é¢„æµ‹æ€§èƒ½æŒ‡æ ‡:
- å¹³å‡é¢„æµ‹è¯¯å·®: {np.mean(prediction_errors):.4f} m
- æœ€å¤§é¢„æµ‹è¯¯å·®: {np.max(prediction_errors):.4f} m  
- è¯¯å·®æ ‡å‡†å·®: {np.std(prediction_errors):.4f} m
- é¢„æµ‹ç²¾åº¦: {(1 - np.mean(prediction_errors)/10)*100:.1f}%

âš¡ èƒ½é‡å®ˆæ’:
- åˆå§‹èƒ½é‡: {energy_history[0]:.2f} J
- æœ€ç»ˆèƒ½é‡: {energy_history[-1]:.2f} J
- èƒ½é‡æŸå¤±: {((energy_history[0] - energy_history[-1])/energy_history[0]*100):.1f}%

ğŸ¬ è§†é¢‘è¾“å‡º: {video_path}
ğŸ“Š æ•°æ®ç‚¹æ•°: {len(prediction_errors)}
â±ï¸  æ¼”ç¤ºæ—¶é•¿: {len(energy_history)*0.016:.1f} ç§’

âœ… æ¼”ç¤ºæˆåŠŸå®Œæˆ!
"""
    
    print(report)
    
    # ä¿å­˜æŠ¥å‘Š
    with open("/root/virtual/advanced_ai_demo_report.txt", "w", encoding='utf-8') as f:
        f.write(report)

if __name__ == "__main__":
    print("ğŸ¯ é«˜çº§AIé¢„æµ‹æ¼”ç¤ºå¯åŠ¨")
    print("=" * 50)
    
    try:
        success = create_advanced_ai_demo()
        if success:
            print("\nğŸ‰ é«˜çº§AIæ¼”ç¤ºå®Œæˆ!")
            print("ğŸ“ æ£€æŸ¥è¾“å‡ºæ–‡ä»¶:")
            print("  - 07_advanced_ai_demo.mp4")
            print("  - advanced_ai_demo_report.txt")
        else:
            print("\nâŒ æ¼”ç¤ºå¤±è´¥")
            
    except Exception as e:
        print(f"\nğŸ’¥ æ¼”ç¤ºè¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
